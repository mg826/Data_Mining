{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 3: Recommender Systems With Dating Data\n",
    "\n",
    "#### MSDS 7331\n",
    "#### RJ Smith, Alex Matsunami, Cory Nichols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Dating is a complex business. Ask anyone who has watched television in recent years; all of the larger general dating sites claim to have the best \"matching\" capabilities. Some even claim to be optimized for farmers or other niche categories part of what we can call the \"dating universe.\" With millions of people utilizing online dating services, it is only natural then to optimize a recommendation system for users to easily find optimal matches or dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source\n",
    "\n",
    "\n",
    "### Data Files\n",
    "\n",
    "Data is available from the following location:\n",
    "http://www.occamslab.com/petricek/data/\n",
    "\n",
    "#### gender.txt\n",
    "\n",
    "UserID -- Dating Site User Identifier\n",
    "Gender -- The Gender (M=Male, F=Female) of the User\n",
    "\n",
    "#### ratings.txt\n",
    "\n",
    "UserID -- Dating Site User Identifier (same as in gender file)\n",
    "ProfileId -- The UserID of the person being rated\n",
    "Raing -- On scale of 1-10 (10 being best), how did the user rate the profile?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we dive into recommender systems, we must ensure our data:\n",
    "\n",
    "1. Is prepared for machine learning algorithms\n",
    "2. Is relevant for our objective: recommending new users for dating consideration\n",
    "\n",
    "Recommender systems normally utilize a set of items or users and items, along with optional features as part of a linear model to predict ratings or calculate similarities between items. Our training set contains a user id, another user that was rated by our user id and a rating or score. This is an interesting dilemma, often not common to recommenders for music or movies. In our case, we essentially have created a user-user matrix. There is an obvious relationship between the users doing the rating and the users being rated which may imply an item-item (user-user) recommender be used. We will investigate multiple recommender models to determine which works the best.\n",
    "\n",
    "Even though our data is in relatively good shape, let's clean up a bit more and see if we can discover any high level relationships or information about the data that is not readily apparently on basic inspection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis and Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook requires GraphLab to run. License can be obtained below, which will then give page with pip install instructions.\n",
    "https://dato.com/download/\n",
    "\n",
    "pip install --upgrade --no-cache-dir https://get.graphlab.com/GraphLab-Create/2.1/richard@smu.edu/XXXX-XXXX-XXXX-XXXX-XXXX-XXXX-XXXX-XXXX/GraphLab-Create-License.tar.gz\n",
    "\n",
    "Afterwards, update Jupyter:\n",
    "conda install ipython-notebook\n",
    "\n",
    "Uncomment the get_dependencies below and run. It will fail on setting the canvas target. Restart the Jupyter notebook, and all should be good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphlab as gl\n",
    "#gl.get_dependencies() #Run first time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "gl.canvas.set_target(\"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\RJSMIT~1.RED\\AppData\\Local\\Temp\\graphlab_server_1471211156.log.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to richard@smu.edu and will expire on August 14, 2017.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Runtime Exception. No files corresponding to the specified path (C:\\Git\\SMU\\Data_Mining\\Lab3_Dating_Recommender\\ratings.dat).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-18553cc8e0ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ratings.dat'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgenders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gender.dat'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\graphlab\\data_structures\\sframe.pyc\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(cls, url, delimiter, header, error_bad_lines, comment_char, escape_char, double_quote, quote_char, skip_initial_space, column_type_hints, na_values, line_terminator, usecols, nrows, skiprows, verbose, nrows_to_infer, **kwargs)\u001b[0m\n\u001b[0;32m   1623\u001b[0m                                   \u001b[0mstore_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1624\u001b[0m                                   \u001b[0mnrows_to_infer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnrows_to_infer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1625\u001b[1;33m                                   **kwargs)[0]\n\u001b[0m\u001b[0;32m   1626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\graphlab\\data_structures\\sframe.pyc\u001b[0m in \u001b[0;36m_read_csv_impl\u001b[1;34m(cls, url, delimiter, header, error_bad_lines, comment_char, escape_char, double_quote, quote_char, skip_initial_space, column_type_hints, na_values, line_terminator, usecols, nrows, skiprows, verbose, store_errors, nrows_to_infer, **kwargs)\u001b[0m\n\u001b[0;32m   1179\u001b[0m                 \u001b[0mglconnect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_server\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_log_progress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mcython_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1181\u001b[1;33m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproxy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_from_csvs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minternal_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparsing_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_hints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1182\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"CSV parsing cancelled\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\graphlab\\cython\\context.pyc\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_cython_trace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[1;31m# To hide cython trace, we re-raise from here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                 \u001b[1;31m# To show the full trace, we do nothing and let exception propagate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Runtime Exception. No files corresponding to the specified path (C:\\Git\\SMU\\Data_Mining\\Lab3_Dating_Recommender\\ratings.dat)."
     ]
    }
   ],
   "source": [
    "ratings = gl.SFrame.read_csv('ratings.dat', header=False, verbose=False)\n",
    "genders = gl.SFrame.read_csv('gender.dat', header=False, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rename our dataset for ease of use and understanding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings.rename({'X1':'user_id',\n",
    "              'X2':'user_rated',\n",
    "              'X3':'score'})\n",
    "\n",
    "genders.rename({'X1':'user_id',\n",
    "              'X2':'gender'})\n",
    "\n",
    "print ratings, genders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right off the bat, we can see our side data contains some unknowns identified as 'U'. Let's visually inspect our data to get an idea about the distribution and frequency of some of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings.show(), genders.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of scores in our dataset ranges from 1 to 10 with a mean score of 5.9 and a median of 6. Roughly 135,000 users provided ratings while 173,000 were rated. Obviously some users are being rated by users who they have also rated. There is quite a bit of variablility in ratings, however, with a standard deviation of 3.1.\n",
    "\n",
    "Our side information in this case, gender, shows that many users in our dataset have an unknown gender. This will affect our recommender's performance should we choose to incorporate side information into our models.\n",
    "\n",
    "Further, because we do not have sexual orientation information, let's explore the dataset a bit more to see if users are rating multiple genders or if we have a more traditional dating situation where females only rate males and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "complete = ratings.join(genders).join(genders,on={'user_rated':'user_id'})\n",
    "complete.rename({'gender.1':'gender_rated'})\n",
    "complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# notice the user rating above -- our female user_id 1 rated another female a 6.\n",
    "# let's split up the ratings and take a look at how and who they are rating\n",
    "\n",
    "female_ratings = complete[complete['gender'] == 'F']['user_id','user_rated','score','gender_rated']\n",
    "male_ratings =  complete[complete['gender'] == 'M']['user_id','user_rated','score','gender_rated']\n",
    "print 'Female ratings:\\n', female_ratings.show(), '\\n\\nMale ratings:\\n', male_ratings.show()\n",
    "print 'Female rating female count: {0}'.format(sum(female_ratings['gender_rated'] =='F'))\n",
    "print 'Male rating male count: {0}'.format(sum(male_ratings['gender_rated'] =='M'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data cleaning looks to be successful. The female set contains ratings from roughly 60,000 female users while the male set contains roughly the same number of users' ratings. Breaking out this dataset based on male to female or female to male recommenders would not be optimal as there are significant amounts of male to male and female to female ratings. \n",
    "\n",
    "Ensuring global orientations are taken into account will be critical for the success of our recommender. Users utilizing our recommender could easily identify their preference (if necessary) upon launching our dating application which will easily filter top recommendations based on gender. We will examine this functionality in detail shortly.\n",
    "\n",
    "Thus, we will not split the dataset. Now let's get to the fun part and take a look at which users are the most popular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling: The Popularity Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's randomly split out our dataset into training and test sets. Since we have roughly 135,000 unique users and our gender distributions are not egregiously uneven, though contain unknowns, utilizing a max number of users equal to ten percent of our dataset should work just fine for testing. This percentage works out to about 13,500 users, however, we'll round up to 14,000. From each of these users, we'll pull 20% of their ratings for our test set and retain the rest of the 80% for training. We use a higher amount for testing ratings here as each randomly selected user could have many, or few, ratings. To be conservative, we want to test on more data to decrease the chance we grab anomalies randomly and receive poor performance ratings on our recommenders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_genders = genders.copy()\n",
    "item_genders = genders.rename({'user_id':'user_rated'})\n",
    "genders.rename({'user_rated':'user_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = gl.recommender.util.random_split_by_user(ratings,\n",
    "                                                       user_id='user_id', item_id='user_rated',\n",
    "                                                       max_num_users=14000, item_test_proportion=0.2)\n",
    "\n",
    "pop = gl.recommender.popularity_recommender.create(train, \n",
    "                                                   user_id='user_id',\n",
    "                                                   item_id='user_rated',\n",
    "                                                   target='score',\n",
    "                                                   verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could feed in side data into our popularity model to take into account the associated genders, ensuring that a linear term for the genders who have been rated (items) are included in our model and capturing the relationship between the ratings and those rated, as there is a natural relationship between the user-user setup in our dataset, though it may not matter much in a popularity model. That being said, the current way our popularity model is set up takes only the highest rated users according to score and recommends them, regardless of gender. We are more interested in establishing a baseline popularity model and will consider side data in more complex models shortly.\n",
    "\n",
    "Let's take a look at the popularity model breakdown quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a unique user list and utilize this list to make some initial recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a unique user list and get top 5 recommendations for the first user\n",
    "user_list = ratings['user_id'].unique()\n",
    "recs = pop.recommend(user_list[5000:5001], k=5)\n",
    "recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recs = recs.join(genders).join(genders, on={'user_rated':'user_id'}).rename({'gender.1':'gender_recommended'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recs.sort('rank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one user, 22915, from the recommended list above, to see who rated them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings[ratings['user_rated'] == 22915].join(genders).join(genders, on={'user_rated':'user_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This user is a male who had mostly known females rate him a 10, lucky guy! However, our popularity model does have some drawbacks. Since we are using rating, we are only taking into account users with the highest mean ratings. The previous user had 237 ratings, but in stark contrast user 120342 is also recommended, however, has only receive ONE rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings[ratings['user_rated'] == 120342].join(genders).join(genders, on={'user_rated':'user_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an obvious limitation of the popularity model based on ratings in GraphLab. However, it will more than suffice as a baseline to test against in the future or use for users where no data is available.\n",
    "\n",
    "However, the five most popular users based on ratings and the number of times they have been rated are users 120342, 88179, 83622, 73611, and 22915. The above query matches the first male user with the five most popular users based on our popularity recommender, who happen to all be male. Our basic popularity recommender is only considering the highest and most frequently rated users in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obviously get back a male to male recommendation situation. However, we do not know the orientation of this user, further the popularity model simply gives us the most popular users, which would not be optimal for all situations, especially in dating. However, using the popularity model as a baseline to compare additional recommenders is not a bad idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_eval = pop.evaluate(test, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Overall RMSE: {0:.3}\\n\\nOverall Precision & Recall by Cutoff:\\n{1}'.format(pop_eval['rmse_overall'],\n",
    "                                                                                  pop_eval['precision_recall_overall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our popularity model across all genders is quite terrible, with extremely low precision and recall. RMSE is not quite as bad, however it is not optimal at predicting user ratings, with an error of roughly two points, meanining on average we are off two rating points. \n",
    "\n",
    "As an aside, if we want to only recommend males to a female, we can perform the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get only known males to restrict recommendations!\n",
    "genders_m = genders[genders['gender']=='M']['user_id']\n",
    "pop.recommend(user_list[0:1], items=genders_m, k=5).join(user_genders).sort('rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# or known females to a male\n",
    "genders_f = genders[genders['gender']=='F']['user_id']\n",
    "pop.recommend(user_list[0:1], items=genders_f, k=5).join(user_genders).sort('rank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, though, we'd need to refine our recommenders to ensure our users have the best recommendations possible. Popularity models are nice for twitter, however, they won't work for dating in most cases. We will now explore more advanced recommendation options and utilize side data to improve our recommendation engine and compare it to the base popularity model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Recommender Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranked Factorization Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first attempt at creating a more robust recommender will be a Ranked Factorization Matrix. Since we have explicit data with ratings included in our observations, we can do one of two things with matrix factorization:\n",
    "\n",
    "1. Predict the rating a user would give\n",
    "2. Recommend items we believe the user would rate highly\n",
    "\n",
    "\n",
    "Many excerpts found from graphlab documentation\n",
    "\n",
    "The RankingFactorizationRecommender in GraphLab tries to recommend items that are both similar to the items in a user's dataset and, if rating information is provided, those that would be rated highly by the user. The trade off with this recommender is that we will likely have less predictive accuracy but better precision and recall. This is due to the fact that the ranking method penalizes the predicted rating of items that are significantly different from the items a user has already interacted with. This ensures the model is confident in its prediction AND it predicts a high rating.\n",
    "\n",
    "In factorization models in general, users and items are represented by weights and factors learned during model training where weights or bias terms account for a user or item's bias towards high or low ratings. An item rated high consistently would have a higher weight coefficient, for instance. There are also latent factor terms that model interactions between users and items and allow us to group users and items into categories. If a user loves romance movies and hates action movies, factor terms attempt to capture that relationship and use the model to predict lower scores for action movies and higher scores for romance movies.\n",
    "\n",
    "This results in a linear model for each user as follows:\n",
    "\n",
    "        score(i,j)=Î¼ + wi + wj + aTxi + bTyj + uTivj\n",
    "        \n",
    "Where w's are learned weights for users and items, a and b represent side data for users and items, respectively and the last term represents the dot product of the latent variables. Mu, represents a global bias term.\n",
    "\n",
    "Weights and latent factors are learned via stochastic gradient descent and solving for the minimization of multiple user/item bias variables, side data variables and latent variables of a complex objective function not listed here. Randomization is often incorporated, especially in the case of finding latent variables where we have missing ratings and want to predict what the user score would be.\n",
    "        \n",
    "With the high level overview out of the way, let's find the latent factors (using SGD) from our known data and set up our penalized linear model using graphlab's RankingFactorizationRecommender. This recommender will learn the latent factors from the data to make recommendation and rank them according to the likelihood of seeing the user, item (or in our case user-user) pair.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_rec = gl.recommender.ranking_factorization_recommender.create(train,\n",
    "                                                                 user_id='user_id',\n",
    "                                                                 item_id='user_rated',\n",
    "                                                                 target='score',\n",
    "                                                                 user_data=genders,\n",
    "                                                                 verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_rec.evaluate(test, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and recall performance is much better with a ranked factorization model rather than a popularity model. However, as mentioned prior, RMSE suffers as we are not optimizing for prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
