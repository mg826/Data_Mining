{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   C   D\n",
       "0   1   2   3   4\n",
       "1   5   6 NaN   8\n",
       "2  10  11  12 NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO # String IO formats strings\n",
    "csv_data = '''A,B,C,D\n",
    "1.0,2.0,3.0,4.0\n",
    "5.0,6.0,,8.0\n",
    "10.0,11.0,12.0'''\n",
    "csv_data = unicode(csv_data)\n",
    "df = pd.read_csv(StringIO(csv_data)) # StringIO allows us to read string assigned to csv_data into a DF as if it were\n",
    "# a regular CSV\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    0\n",
      "B    0\n",
      "C    1\n",
      "D    1\n",
      "dtype: int64\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# we can use the .isnull method to return a DataFrame with boolean values that indicate whether a cell contains a\n",
    "# numeric value (False) or if data is missing (True)\n",
    "# we can sum up the null values in each column using sum\n",
    "print df.isnull().sum(axis = 0) # calculate sums row wise - agg data will be represented by column\n",
    "print df.isnull().sum(axis = 1) # calculate sums column wise - agg data will be represented by rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminating samples or features with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B\n",
       "0   1   2\n",
       "1   5   6\n",
       "2  10  11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove rows with dropna()\n",
    "# df.dropna() by default drops rows with nas in them\n",
    "# remove features with dropna(axis=1)\n",
    "df.dropna(axis = 1) # drop columns column wise - if any NAs then drop column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   C   D\n",
       "0   1   2   3   4\n",
       "2  10  11  12 NaN"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only drop rows where all columns are NaN\n",
    "df.dropna(how= 'all')\n",
    "# drop rows that have not at least 4 non-NaN values\n",
    "df.dropna(thresh=4)\n",
    "# only drop rows where NaN appear in specific columns (here: 'C')\n",
    "df.dropna(subset=['C'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "removing missing data seems to be a convenient approach, it comes with disadvantages like removing too many samples\n",
    "removing too many features or too much data can ruin the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing Missing Values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can use different interpolation techniques to estimate the missing values from other training samples\n",
    "one method is mean imputation, replace missing value by mean value of the entire feature column\n",
    "can use the imputer submodule from scikit learn\n",
    "other strategies include: 'median', 'most_frequent' and others, most_frequent is useful for categorical feature filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   C   D\n",
       "0   1   2   3   4\n",
       "1   5   6 NaN   8\n",
       "2  10  11  12 NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data = '''A,B,C,D\n",
    "1.0,2.0,3.0,4.0\n",
    "5.0,6.0,,8.0\n",
    "10.0,11.0,12.0'''\n",
    "csv_data = unicode(csv_data)\n",
    "df = pd.read_csv(StringIO(csv_data)) # StringIO allows us to read string assigned to csv_data into a DF as if it were\n",
    "# a regular CSV\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1. ,   2. ,   3. ,   4. ],\n",
       "       [  5. ,   6. ,   7.5,   8. ],\n",
       "       [ 10. ,  11. ,  12. ,   6. ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imr = Imputer(missing_values='NaN', strategy ='mean', axis = 0)\n",
    "imr = imr.fit(df)\n",
    "imputed_data = imr.transform(df.values)\n",
    "imputed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(imputed_data, columns = ['A','B','C','D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B     C  D\n",
       "0   1   2   3.0  4\n",
       "1   5   6   7.5  8\n",
       "2  10  11  12.0  6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Ordinal Features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ordinal features are categorical with an order, we do not need to one-hot encode these as their order can be\n",
    "maintained in a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>XL</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color size  price classlabel\n",
       "0  green    M   10.1     class1\n",
       "1    red    L   13.5     class2\n",
       "2   blue   XL   15.3     class1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame([['green', 'M', 10.1, 'class1'],\n",
    "                  ['red', 'L', 13.5, 'class2'],\n",
    "                  ['blue', 'XL', 15.3, 'class1']], \n",
    "                  columns = ['color','size','price','classlabel'])\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's manually map the ordinal features of size\n",
    "We know there are 3 unique values: M, L, XL with a natural ordering from least to greatest, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values are:  ['L' 'M' 'XL']\n"
     ]
    }
   ],
   "source": [
    "print 'unique values are: ', np.unique(df['size'].values)\n",
    "# create a dict mapping for string values to integers\n",
    "size_mapping = {'XL':3, 'L':2, 'M':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  size  price classlabel\n",
       "0  green     1   10.1     class1\n",
       "1    red     2   13.5     class2\n",
       "2   blue     3   15.3     class1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .map is a method that takes each value in an array and maps it to a lookup such as the dict just defined\n",
    "df['size'] = df['size'].map(size_mapping)\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can also get to the inverse of the size mapping, by transposing the dict through a dict comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>XL</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color size  price classlabel\n",
       "0  green    M   10.1     class1\n",
       "1    red    L   13.5     class2\n",
       "2   blue   XL   15.3     class1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_size_mapping = {v:k for k,v in size_mapping.items()} # use a dict comprehension to create reverse mapping\n",
    "df['size'] = df['size'].map(inv_size_mapping) # re-map the reverse mapping back to df['size']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Class Variables"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's map our class values to integers so they work better with learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class1': 0, 'class2': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets use another dictionary comprehension to do this manually\n",
    "class_mapping = {label:idx for idx, label in enumerate(np.unique(df['classlabel']))} # make sure to use np.unique\n",
    "class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now replace the classlabel feature with the new integer mapped class label feature\n",
    "df['classlabel'] = df['classlabel'].map(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>XL</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color size  price  classlabel\n",
       "0  green    M   10.1           0\n",
       "1    red    L   13.5           1\n",
       "2   blue   XL   15.3           0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Class Labels With SciKit Learn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can also use scikit learn to encode class labels directly using sklearn.preprocessing import LabelEncoder\n",
    "Instantiate a labelencoder with transvariable = LabelEncoder()\n",
    "Can transform the class labels with df['class'] = transvariable.fit_transform(df['class'])\n",
    "Can back transform with transvariable.inverse_transform(df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>XL</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color size  price classlabel\n",
       "0  green    M   10.1     class1\n",
       "1    red    L   13.5     class2\n",
       "2   blue   XL   15.3     class1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([['green', 'M', 10.1, 'class1'],\n",
    "                  ['red', 'L', 13.5, 'class2'],\n",
    "                  ['blue', 'XL', 15.3, 'class1']], \n",
    "                  columns = ['color','size','price','classlabel'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   color size  price  classlabel\n",
      "0  green    M   10.1           0\n",
      "1    red    L   13.5           1\n",
      "2   blue   XL   15.3           0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>XL</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color size  price classlabel\n",
       "0  green    M   10.1     class1\n",
       "1    red    L   13.5     class2\n",
       "2   blue   XL   15.3     class1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "class_le = LabelEncoder()\n",
    "df['classlabel'] = class_le.fit_transform(df['classlabel']) # fit_transform is a shortcut for calling fit and transform\n",
    "print df\n",
    "# separately, and we can use inverse_transform method to transform the int class labels back to original string rep\n",
    "df['classlabel'] = class_le.inverse_transform(df['classlabel'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Handling Nominal Features With One-Hot Encoding"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We must be cognizant of the fact that nominal features have no ordering\n",
    "We cannot simply relabel with integers in a single column because machine learning algorithms will consider any ordering as differences between categories, when there are not any difference in nominal variables\n",
    "\n",
    "Instead, we should create new dummy features for each unique value of the nominal attribute\n",
    "e.g. converting a color feature with blue, green and red to three features with binary values\n",
    "For example, in the red column each time we have a red, we have 1, all other non-reds will be zero\n",
    "In the blue column, each time we encounter a blue label in the color column, blue column will be represented with 1, all other columns (red, green) will be zero and so on.\n",
    "\n",
    "We can use the OneHotEncoder that is implemented in the scikit-learn.preprocessing module - only takes integers\n",
    "Pandas actually has an easier method called pandas.get_dummies - takes class labels and numbers\n",
    "If we want to use the SKLEARN OneHotEncoder, we will need to pass a matrix of integers to the instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "      <th>blue</th>\n",
       "      <th>green</th>\n",
       "      <th>red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>XL</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color size  price classlabel  blue  green  red\n",
       "0      0    M   10.1     class1     1      0    0\n",
       "1      1    L   13.5     class2     0      1    0\n",
       "2      2   XL   15.3     class1     0      0    1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "df = pd.DataFrame([['green', 'M', 10.1, 'class1'],\n",
    "                  ['red', 'L', 13.5, 'class2'],\n",
    "                  ['blue', 'XL', 15.3, 'class1']], \n",
    "                  columns = ['color','size','price','classlabel'])\n",
    "#df.values\n",
    "#df[['blue','green','red']] = pd.get_dummies(df['color'])\n",
    "\n",
    "#pd.get_dummies(df[['price','color']])\n",
    "# the get_dummies method wil only convert string columns and leave all other columns unchanged\n",
    "int_map = {v:k for k,v in enumerate(df['color'])}\n",
    "df['color'] = df['color'].map(int_map)\n",
    "\n",
    "df[['blue','green','red']] = pd.get_dummies(df['color'])\n",
    "df\n",
    "#ohe = OneHotEncoder(categorical_features=[0])\n",
    "#test = ohe.fit_transform(df['color'].values).toarray()\n",
    "#test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioning Dataset Into Training Using Wine Data\n",
    "##### Look at the chemical makeup of 178 wine samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_label</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanine</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>ODQ280/OD315</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_label  alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  \\\n",
       "0            1    14.23        1.71  2.43               15.6        127   \n",
       "1            1    13.20        1.78  2.14               11.2        100   \n",
       "2            1    13.16        2.36  2.67               18.6        101   \n",
       "3            1    14.37        1.95  2.50               16.8        113   \n",
       "4            1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanine  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   color_intensity   hue  ODQ280/OD315  proline  \n",
       "0             5.64  1.04          3.92     1065  \n",
       "1             4.38  1.05          3.40     1050  \n",
       "2             5.68  1.03          3.17     1185  \n",
       "3             7.80  0.86          3.45     1480  \n",
       "4             4.32  1.04          2.93      735  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\n",
    "df_wine.columns = ['class_label','alcohol','malic_acid','ash','alcalinity_of_ash','magnesium','total_phenols',\n",
    "                  'flavanoids','nonflavanoid_phenols','proanthocyanine','color_intensity','hue','ODQ280/OD315',\n",
    "                  'proline']\n",
    "df_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_label</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanine</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>ODQ280/OD315</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.938202</td>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.775035</td>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class_label     alcohol  malic_acid         ash  alcalinity_of_ash  \\\n",
       "count   178.000000  178.000000  178.000000  178.000000         178.000000   \n",
       "mean      1.938202   13.000618    2.336348    2.366517          19.494944   \n",
       "std       0.775035    0.811827    1.117146    0.274344           3.339564   \n",
       "min       1.000000   11.030000    0.740000    1.360000          10.600000   \n",
       "25%       1.000000   12.362500    1.602500    2.210000          17.200000   \n",
       "50%       2.000000   13.050000    1.865000    2.360000          19.500000   \n",
       "75%       3.000000   13.677500    3.082500    2.557500          21.500000   \n",
       "max       3.000000   14.830000    5.800000    3.230000          30.000000   \n",
       "\n",
       "        magnesium  total_phenols  flavanoids  nonflavanoid_phenols  \\\n",
       "count  178.000000     178.000000  178.000000            178.000000   \n",
       "mean    99.741573       2.295112    2.029270              0.361854   \n",
       "std     14.282484       0.625851    0.998859              0.124453   \n",
       "min     70.000000       0.980000    0.340000              0.130000   \n",
       "25%     88.000000       1.742500    1.205000              0.270000   \n",
       "50%     98.000000       2.355000    2.135000              0.340000   \n",
       "75%    107.000000       2.800000    2.875000              0.437500   \n",
       "max    162.000000       3.880000    5.080000              0.660000   \n",
       "\n",
       "       proanthocyanine  color_intensity         hue  ODQ280/OD315      proline  \n",
       "count       178.000000       178.000000  178.000000    178.000000   178.000000  \n",
       "mean          1.590899         5.058090    0.957449      2.611685   746.893258  \n",
       "std           0.572359         2.318286    0.228572      0.709990   314.907474  \n",
       "min           0.410000         1.280000    0.480000      1.270000   278.000000  \n",
       "25%           1.250000         3.220000    0.782500      1.937500   500.500000  \n",
       "50%           1.555000         4.690000    0.965000      2.780000   673.500000  \n",
       "75%           1.950000         6.200000    1.120000      3.170000   985.000000  \n",
       "max           3.580000        13.000000    1.710000      4.000000  1680.000000  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "the samples belong to 1 of 3 classes (1,2,3) which refer to the three different types of grapes grown in Italy\n",
    "a convenient wway to randomly paritition the data set into separate test and training sets is to use the \n",
    "train_test_split function from sklearn's cross_validation submodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split up the data into training and test sets\n",
    "# separate out class labels\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x, y = df_wine.iloc[:,1:].values, df_wine.iloc[:,0].values\n",
    "# split @ 30% for training set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Need to be cautious in splitting data: too large of a training set will lead to inaccurate generalization accuracy\n",
    "while too large of a test set may not train the model effectively, common split sizes are 80/20, 70/30, 90/10\n",
    "If we have a very large dataset (say 1M+ records) then a split of 95/5 or 99/1 may be satisfactory, this will give\n",
    "the model more data to train on, which is always a good thing\n",
    "\n",
    "One important note: we can reuse the entire data set to better train the classifier once we accept a model formed\n",
    "from the training dataset to optimize the classifier / alogrithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing Features Onto The Same Scale"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Feature scaling is extremely important but easily forgotten\n",
    "Decision trees and random forests are some of the very few machine learning algorithms where we dont need to worry about feature scaling. \n",
    "Most ML algorithms perform much better if features are scaled\n",
    "\n",
    "A feature scaled from 1 to 10 vs a feature scaled from 1 to 1MM will have major effects on algorithms\n",
    "Euclidean distances will be larger in the second feature, dominating algorithms like K-Nearest Neighbors\n",
    "\n",
    "There are two common approaches to bringing different features onto the same scale: normalization and standardization\n",
    "\n",
    "Normalization: Features scaled in range [0,1]\n",
    "    Simple min/max scaling: xi(norm) = (x(i) - x(min)) / (x(max) - x(min))\n",
    "    Where x(i) is the particular sample value in the feature column vector, x(min) is the minimum value in the feature column vector and x(max) is the largest feature value in the column vector\n",
    "    Normalization useful when values need to be bounded\n",
    "\n",
    "Standardization is more practial for Machine Learning algorithms\n",
    "This is because many linear models, such as logistic regression and SVM initialize the weights to 0 or small random\n",
    "values close to zero\n",
    "Using standardization, we center the features columns at mean 0 with standard deviation 1 so the feature columns take the form of a normal distribution which makes it easier to learn the weights\n",
    "\n",
    "    Standardization equation: x(istd) = x(i) - mean of x / standard deviation of x\n",
    "    where means and standard deviations are aggregate means and standard deviations of column vectors\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.72043011,  0.31989247,  0.60215054,  0.57258065,  0.76075269])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can use the minmax scaler from sklearn or do it ourselves if we want to\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "x_train_norm = mms.fit_transform(x_train)\n",
    "x_test_norm = mms.transform(x_test) # apply same fit to the test set (always the case here)\n",
    "x_train_norm[:5,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.91083058, -0.95609928,  0.35952243,  0.22169539,  1.09877654])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train_std = scaler.fit_transform(x_train)\n",
    "x_test_std = scaler.transform(x_test)\n",
    "x_train_std[:5,0] # take a look at first 5 records for first feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Meaningful Features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If we notice a model performs much better on a training dataset than on the test dataset, this observation is a strong indicator for overfitting. \n",
    "\n",
    "Overfitting means that model fits the parameters too closely to the particular data but does not generalize well to real data - the model has a high variance\n",
    "\n",
    "Variance measures the consistency or variability of the model prediction for a particular sample instance if we would retrain the model multiple times (for example on different subsets of the training set) - model could be sensitive to randomness in the data\n",
    "\n",
    "Bias measures how far off the predictions are from the correct values in general if we rebuild the model multiple times on different training datasets - bias is the measure of the systematic error not due to randomness\n",
    "\n",
    "A reason for overfitting is that our model is too complex for the given training data and common solutions to reduce the generalization error are listed as follows:\n",
    "\n",
    "    Collect more training data\n",
    "    Introduce a penalty for complexity via regularlization\n",
    "    Choose a simpler model with fewer parameters\n",
    "    Reduce the dimensionality of the data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Methods to Reduce Overfitting: L1 and L2 regularlization! - Require standard scaled data\n",
    "One good way of finding a good bias-variance tradeoff is to tune complexity via regularlization (handles collinearity, filters out noise and prevents overfitting)\n",
    "\n",
    "Goal: Introduce additional information (bias) to penalize extreme parameter weights. L2 most common. reduce complexity and de-emphasize variables that are truly not important in the model\n",
    "Encourages smaller weights, increasing the regularlization parameter, we shrink weights toward zero and decrease the dependence of our model on the training data\n",
    "\n",
    "L2 model: tau/2||w||^2 = tau/2 for each m sum over all js \n",
    "\n",
    "tau is the so called regularlization parameter, we just add the regularlization term to the cost function for Logistic regression to shrink the weights\n",
    "\n",
    "Via the regularlization parameter, we can control how well we fit the training data while keeping the weights small, by increasing tau, we increase regularlization strength\n",
    "\n",
    "L2 regularlization is one approach to reduce complexity of a model by penalizing large individual weights, where we defined the L2 norm o our weight vector w as follows:\n",
    "\n",
    "L2: || w || ^2 2 = for each m with j observations sum over m where each observation w is \n",
    "\n",
    "L1 regularlization L1: ||w||1 = sum over m for all js|wj| where we simply replace the square of the weights with the sum of the absolute values of the weights\n",
    "\n",
    "L1 regularlization yields sparse feature vectors where most feature weights will be zero, which can be useful with very high dimensional data where most features are irrelevant or outnumber the samples\n",
    "Regularlization can be thought of as adding a penalty term to the cost function to encourage smaller weights, or in other words, penalize larger weights. Idea is to minimize a cost function via a combination of weight coefficients on training data\n",
    "\n",
    "The main goal is to minimize the sum of the unpenalized cost function plus the penalty term which can be understood as adding bias and perferring a simpler model to reduce the variance in the absence of sufficient training data to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.983870967742\n",
      "Test Accuracy:  0.981481481481\n"
     ]
    }
   ],
   "source": [
    "# for regularlized models in sklearn, we can simply set the penalty to '11' to yield a sparse L1 solution\n",
    "# lets train a logistic regression model with an L1 penalty to eliminate the non-important weights of variables\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(penalty='l1',C=0.1)\n",
    "lr.fit(x_train_std, y_train)\n",
    "print 'Training accuracy: ', lr.score(x_train_std, y_train)\n",
    "print 'Test Accuracy: ', lr.score(x_test_std, y_test)\n",
    "# these models indicate no overfitting, the test accuracy is BETTER than training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
