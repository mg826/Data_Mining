{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Data Set, More Practice With Pandas\n",
    "## Cory Nichols - MSDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male   22      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                             Heikkinen, Miss. Laina  female   26      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
       "4                           Allen, Mr. William Henry    male   35      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# represent nominal and ordinal attributes first\n",
    "# how we represent data types in computer is very specific\n",
    "# workbook for titanic data, about 1K people on Titanic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/titanic.csv')\n",
    "\n",
    "# lets look at data types\n",
    "df.head()\n",
    "# class, name, sex, age, sibiling or spouse #, ticket, fare, cabin, embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 90.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# all continuous attributes\n",
    "# describes data types, floats represent continuous attributes: interval and ratio\n",
    "# ints represent ordinals normally\n",
    "df.describe()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.61616161616161"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of people that died on titanic\n",
    "# length of data frame where people died divided by total amt\n",
    "float(len(df[df.Survived==0]))/ len(df) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass\n",
      "1    136\n",
      "2     87\n",
      "3    119\n",
      "Name: Survived, dtype: int64\n",
      "----------------------------\n",
      "Pclass\n",
      "1    216\n",
      "2    184\n",
      "3    491\n",
      "Name: Survived, dtype: int64\n",
      "----------------------------\n",
      "Pclass\n",
      "1    62.962963\n",
      "2    47.282609\n",
      "3    24.236253\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# group by class person came from\n",
    "# not a complete list, but a good representation of 1K+ passengers\n",
    "df_grouped = df.groupby('Pclass')\n",
    "# get the sum of those who survived\n",
    "print df_grouped.Survived.sum() # where 1 = survived or event\n",
    "print '----------------------------'\n",
    "# count all of the records where we have a survived status\n",
    "print df_grouped.Survived.count()\n",
    "print '----------------------------'\n",
    "# get percentage of people who survived by what class theyre in and what ticket was purchased\n",
    "print (df_grouped.Survived.sum() / df_grouped.Survived.count()) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       714\n",
       "unique        3\n",
       "top       adult\n",
       "freq        606\n",
       "Name: age_range, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to break up the age variable into buckets? use pd.cut\n",
    "# for 3 buckets, must have 4 numbers in range in this case to set boundaries\n",
    "# e.g., children are 0 to 15, adults 16 to 64, seniors 65 and older (1e6 so 1000000 1M)\n",
    "df['age_range'] = pd.cut(df.Age,[0, 16, 65, 1e6],3, labels=['child', 'adult', 'senior'])\n",
    "df.age_range.describe()\n",
    "# 714 records are classified\n",
    "# 3 unique types (child, adult, senior)\n",
    "# top frequency category is adult with 606 instances or objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of survivors in each group\n",
      "Pclass  age_range\n",
      "1       child        88.888889\n",
      "        adult        65.317919\n",
      "        senior       25.000000\n",
      "2       child        90.476190\n",
      "        adult        42.666667\n",
      "        senior        0.000000\n",
      "3       child        40.000000\n",
      "        adult        20.141343\n",
      "        senior        0.000000\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# now lets group by class and age range, then look at survival rate\n",
    "df_grouped = df.groupby(['Pclass', 'age_range'])\n",
    "print 'Percentage of survivors in each group'\n",
    "print df_grouped.Survived.sum() / df_grouped.Survived.count() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Age        Fare       Parch    Survived\n",
      "Pclass SibSp                                                      \n",
      "1      0     count  113.000000  137.000000  137.000000  137.000000\n",
      "             mean    39.181416   75.223356    0.270073    0.562044\n",
      "             std     14.844591   87.103081    0.575270    0.497956\n",
      "             min      4.000000    0.000000    0.000000    0.000000\n",
      "             25%     28.000000   27.720800    0.000000    0.000000\n",
      "             50%     37.000000   39.600000    0.000000    1.000000\n",
      "             75%     50.000000   80.000000    0.000000    1.000000\n",
      "             max     80.000000  512.329200    2.000000    1.000000\n",
      "       1     count   65.000000   71.000000   71.000000   71.000000\n",
      "             mean    37.414154   88.492021    0.422535    0.746479\n",
      "             std     14.690355   40.307129    0.786711    0.438123\n",
      "             min      0.920000   39.600000    0.000000    0.000000\n",
      "             25%     28.000000   56.414600    0.000000    0.500000\n",
      "             50%     38.000000   79.200000    0.000000    1.000000\n",
      "             75%     49.000000  108.900000    1.000000    1.000000\n",
      "             max     70.000000  263.000000    4.000000    1.000000\n",
      "       2     count    5.000000    5.000000    5.000000    5.000000\n",
      "             mean    37.200000  159.975840    0.800000    0.800000\n",
      "             std     16.513631   97.893264    1.095445    0.447214\n",
      "             min     18.000000   51.479200    0.000000    0.000000\n",
      "             25%     21.000000   90.000000    0.000000    1.000000\n",
      "             50%     44.000000  133.650000    0.000000    1.000000\n",
      "             75%     50.000000  262.375000    2.000000    1.000000\n",
      "             max     53.000000  262.375000    2.000000    1.000000\n",
      "       3     count    3.000000    3.000000    3.000000    3.000000\n",
      "             mean    22.000000  263.000000    2.000000    0.666667\n",
      "             std      2.645751    0.000000    0.000000    0.577350\n",
      "             min     19.000000  263.000000    2.000000    0.000000\n",
      "             25%     21.000000  263.000000    2.000000    0.500000\n",
      "             50%     23.000000  263.000000    2.000000    1.000000\n",
      "...                        ...         ...         ...         ...\n",
      "3      3     std     10.260013    3.811647    0.621582    0.288675\n",
      "             min      2.000000   15.850000    0.000000    0.000000\n",
      "             25%      2.750000   21.075000    1.000000    0.000000\n",
      "             50%      6.000000   25.466700    1.000000    0.000000\n",
      "             75%      9.250000   27.900000    2.000000    0.000000\n",
      "             max     33.000000   27.900000    2.000000    1.000000\n",
      "       4     count   18.000000   18.000000   18.000000   18.000000\n",
      "             mean     7.055556   31.855556    1.500000    0.166667\n",
      "             std      4.880601    7.322546    0.514496    0.383482\n",
      "             min      1.000000    7.925000    1.000000    0.000000\n",
      "             25%      3.250000   29.662500    1.000000    0.000000\n",
      "             50%      6.500000   31.275000    1.500000    0.000000\n",
      "             75%      9.000000   37.612500    2.000000    0.000000\n",
      "             max     17.000000   39.687500    2.000000    1.000000\n",
      "       5     count    5.000000    5.000000    5.000000    5.000000\n",
      "             mean    10.200000   46.900000    2.000000    0.000000\n",
      "             std      5.805170    0.000000    0.000000    0.000000\n",
      "             min      1.000000   46.900000    2.000000    0.000000\n",
      "             25%      9.000000   46.900000    2.000000    0.000000\n",
      "             50%     11.000000   46.900000    2.000000    0.000000\n",
      "             75%     14.000000   46.900000    2.000000    0.000000\n",
      "             max     16.000000   46.900000    2.000000    0.000000\n",
      "       8     count    0.000000    7.000000    7.000000    7.000000\n",
      "             mean          NaN   69.550000    2.000000    0.000000\n",
      "             std           NaN    0.000000    0.000000    0.000000\n",
      "             min           NaN   69.550000    2.000000    0.000000\n",
      "             25%           NaN   69.550000    2.000000    0.000000\n",
      "             50%           NaN   69.550000    2.000000    0.000000\n",
      "             75%           NaN   69.550000    2.000000    0.000000\n",
      "             max           NaN   69.550000    2.000000    0.000000\n",
      "\n",
      "[120 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# missing values always common, third class left out, data may not be pertinent, not applicable, eg childrens income\n",
    "# must take statistics into account for machine learning algorithms\n",
    "# imputation based on specific cuts of the data, for instance based on class and sibling spouse\n",
    "# data may not be collected, e.g. third class details seem to be lacking\n",
    "# how do we fill in the values for age based on other demographics?\n",
    "del df['PassengerId']\n",
    "del df['Name']\n",
    "del df['Cabin']\n",
    "del df['Ticket']\n",
    "\n",
    "df_grouped = df.groupby(['Pclass', 'SibSp'])\n",
    "print df_grouped.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Survived  Age  Parch      Fare\n",
      "0           0   22      0    7.2500\n",
      "1           1   38      0   71.2833\n",
      "2           1   26      0    7.9250\n",
      "3           1   35      0   53.1000\n",
      "4           0   35      0    8.0500\n",
      "5           0   26      0    8.4583\n",
      "6           0   54      0   51.8625\n",
      "7           0    2      1   21.0750\n",
      "8           1   27      2   11.1333\n",
      "9           1   14      0   30.0708\n",
      "10          1    4      1   16.7000\n",
      "11          1   58      0   26.5500\n",
      "12          0   20      0    8.0500\n",
      "13          0   39      5   31.2750\n",
      "14          0   14      0    7.8542\n",
      "15          1   55      0   16.0000\n",
      "16          0    2      1   29.1250\n",
      "17          1   30      0   13.0000\n",
      "18          0   31      0   18.0000\n",
      "19          1   26      0    7.2250\n",
      "20          0   35      0   26.0000\n",
      "21          1   34      0   13.0000\n",
      "22          1   15      0    8.0292\n",
      "23          1   28      0   35.5000\n",
      "24          0    8      1   21.0750\n",
      "25          1   38      5   31.3875\n",
      "26          0   26      0    7.2250\n",
      "27          0   19      2  263.0000\n",
      "28          1   26      0    7.8792\n",
      "29          0   26      0    7.8958\n",
      "..        ...  ...    ...       ...\n",
      "861         0   21      0   11.5000\n",
      "862         1   48      0   25.9292\n",
      "863         0  NaN      2   69.5500\n",
      "864         0   24      0   13.0000\n",
      "865         1   42      0   13.0000\n",
      "866         1   27      0   13.8583\n",
      "867         0   31      0   50.4958\n",
      "868         0   26      0    9.5000\n",
      "869         1    4      1   11.1333\n",
      "870         0   26      0    7.8958\n",
      "871         1   47      1   52.5542\n",
      "872         0   33      0    5.0000\n",
      "873         0   47      0    9.0000\n",
      "874         1   28      0   24.0000\n",
      "875         1   15      0    7.2250\n",
      "876         0   20      0    9.8458\n",
      "877         0   19      0    7.8958\n",
      "878         0   26      0    7.8958\n",
      "879         1   56      1   83.1583\n",
      "880         1   25      1   26.0000\n",
      "881         0   33      0    7.8958\n",
      "882         0   22      0   10.5167\n",
      "883         0   28      0   10.5000\n",
      "884         0   25      0    7.0500\n",
      "885         0   39      5   29.1250\n",
      "886         0   27      0   13.0000\n",
      "887         1   19      0   30.0000\n",
      "888         0   25      2   23.4500\n",
      "889         1   26      0   30.0000\n",
      "890         0   32      0    7.7500\n",
      "\n",
      "[891 rows x 4 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 7 columns):\n",
      "Survived    891 non-null int64\n",
      "Age         884 non-null float64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "Pclass      891 non-null int64\n",
      "SibSp       891 non-null int64\n",
      "Sex         891 non-null object\n",
      "dtypes: float64(2), int64(4), object(1)\n",
      "memory usage: 55.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# imputation: lambda function fills in missing values\n",
    "# lambda is an anonymous function\n",
    "# go into each group, call lambda\n",
    "# call grp.fillna, any time we see a # fill with median of group to class\n",
    "# My takeout so far is that .transform will work (or deal) with Series (columns) in isolation from each other. \n",
    "# transform will look at the dataframe columns one by one and return back a series (or group of series) 'made' \n",
    "# of scalars which are repeated len(input_column) times.\n",
    "# transform gets rid of data grouping to give original data set in original ordering\n",
    "# http://stackoverflow.com/questions/27517425/apply-vs-transform-on-a-group-object\n",
    "df_imputed = df_grouped.transform(lambda grp: grp.fillna(grp.median()))\n",
    "print df_imputed\n",
    "# add back in PClass and SibSp\n",
    "df_imputed[['Pclass', 'SibSp']] = df[['Pclass','SibSp']]\n",
    "df_imputed['Sex'] = df['Sex']\n",
    "\n",
    "print df_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      "Survived     891 non-null int64\n",
      "Age          884 non-null float64\n",
      "Parch        891 non-null int64\n",
      "Fare         891 non-null float64\n",
      "Pclass       891 non-null int64\n",
      "SibSp        891 non-null int64\n",
      "Sex          891 non-null object\n",
      "age_range    884 non-null category\n",
      "dtypes: category(1), float64(2), int64(4), object(1)\n",
      "memory usage: 56.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_imputed['age_range'] = pd.cut(df_imputed.Age,[0,16,65,1e6], 3, labels = ['child', 'adult', 'senior'])\n",
    "print df_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 884 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      "Survived     884 non-null int64\n",
      "Age          884 non-null float64\n",
      "Parch        884 non-null int64\n",
      "Fare         884 non-null float64\n",
      "Pclass       884 non-null int64\n",
      "SibSp        884 non-null int64\n",
      "Sex          884 non-null object\n",
      "age_range    884 non-null category\n",
      "dtypes: category(1), float64(2), int64(4), object(1)\n",
      "memory usage: 56.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# eliminate entries that still have empty values\n",
    "# if missing value, delete it\n",
    "df_imputed.dropna(inplace=True)\n",
    "df_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Survivors in Each Group, With Imputed Values\n",
      "Pclass  age_range\n",
      "1       child        88.888889\n",
      "        adult        62.561576\n",
      "        senior       25.000000\n",
      "2       child        90.476190\n",
      "        adult        42.236025\n",
      "        senior        0.000000\n",
      "3       child        37.837838\n",
      "        adult        22.303922\n",
      "        senior        0.000000\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# imputed falls off like a poop\n",
    "df_grouped = df_imputed.groupby(['Pclass','age_range'])\n",
    "print 'Percentage of Survivors in Each Group, With Imputed Values'\n",
    "print df_grouped.Survived.sum() / df_grouped.Survived.count() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Survived         Age      Pclass        Fare\n",
      "count  884.000000  884.000000  884.000000  884.000000\n",
      "mean     0.386878    0.362684    0.651584    0.062281\n",
      "std      0.487311    0.167234    0.418550    0.097161\n",
      "min      0.000000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    0.271174    0.500000    0.015412\n",
      "50%      0.000000    0.321438    1.000000    0.028213\n",
      "75%      1.000000    0.459663    1.000000    0.059532\n",
      "max      1.000000    1.000000    1.000000    1.000000\n"
     ]
    }
   ],
   "source": [
    "# normalize all of the attributes to fit on SAME SCALE: in this case between 0 and 1, primitive way\n",
    "# by taking the value - the minimum of all of the values / max of all values - min of all values\n",
    "# e.g. min not be zero or max be 10,000 on one var and min of 5MM and max of 100MM on another\n",
    "# basically places all variables on same scale\n",
    "# subtract off min, divide by max\n",
    "# everything b/w 0 and 1 using this method\n",
    "# data doesnt have to fit completely into memory to call the functions\n",
    "# however, normally we need zero mean and unit SD, truly normal data set, divide by the standard deviation\n",
    "# but here is this method anyway!!11\n",
    "\n",
    "df_sub = df_imputed[['Survived','Age','Pclass','Fare']]\n",
    "df_normalized = (df_sub-df_sub.min())/(df_sub.max()-df_sub.min()) # call min and max on top of DF\n",
    "\n",
    "print df_normalized.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.]\n",
      "[ -4.11937955e-17   2.49172226e-16   2.13002064e-16   8.03781375e-17]\n",
      "-0.130086567071\n"
     ]
    }
   ],
   "source": [
    "# let's normalize data with a mean of 0 and standard deviation of 0\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a pure data matrix with values\n",
    "df_matrix = df_imputed[['Survived', 'Age', 'Pclass', 'Fare']].values\n",
    "\n",
    "# call standardscaler.fit_transform to normalize entire matrix with mean of 0 and stddev of 1\n",
    "s_obj = StandardScaler()\n",
    "\n",
    "# create a matrix of normalized values from previously untransformed values\n",
    "df_matrix_norm = s_obj.fit_transform(df_matrix)\n",
    "\n",
    "# call axis = 0 for each variables' statistics\n",
    "#print np.std(df_matrix_norm, axis = 0) # 0 is column, 1 is row, nothing is aggregate\n",
    "#print np.mean(df_matrix_norm, axis= 0)\n",
    "\n",
    "print df_matrix_norm.std(axis=0)\n",
    "print df_matrix_norm.mean(axis=0)\n",
    "\n",
    "# lets fit the other data and transform a new data set with it\n",
    "df_fitter = s_obj.fit(df_matrix)\n",
    "test= np.array([1.0,2.0,3.0,4.0])\n",
    "scaler = df_fitter.transform(test)\n",
    "print np.mean(scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Representing Categorical Variables with One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmpdf = pd.get_dummies(df['Sex'], prefix='gender')\n",
    "tmpdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmpdf = pd.get_dummies(df_imputed['Pclass'], prefix = 'class')\n",
    "tmpdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import plotting functionality\n",
    "# bar charts, scatters, advanced plots\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "%matplotlib inline \n",
    "# any graphics generated embedded into HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_grouped = df_imputed.groupby(['Pclass','age_range'])\n",
    "survival_rate = df_grouped.Survived.sum() / df_grouped.Survived.count()\n",
    "# all we need is to plot survival_rate.plot() and pass a kind = bar horizontal\n",
    "ax = survival_rate.plot(kind='barh')\n",
    "print survival_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lets use crosstab\n",
    "# create a cross tab by PClass and Age_Range, with true/false for survived\n",
    "survival = pd.crosstab([df_imputed['Pclass'], df_imputed['age_range']], df_imputed.Survived.astype(bool))\n",
    "print survival\n",
    "# # of times survived attribute was false or true\n",
    "# change to percentages, divide survival type into totals\n",
    "survival_rate = survival.div(survival.sum(1).astype(float), axis=0)\n",
    "print survival_rate\n",
    "survival_rate.plot(kind='barh', stacked=True, color=['black','gold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_imputed\n",
    "survival_counts = pd.crosstab([df_imputed['Pclass'], df_imputed['Sex']], df_imputed.Survived.astype(bool))\n",
    "print survival_counts\n",
    "survival_counts.plot(kind='bar', stacked=True, color = ['black','gold'])\n",
    "\n",
    "survival_rate = survival.div(survival.sum(1).astype(float), axis = 0)\n",
    "survival_rate.plot(kind = 'barh', stacked=True, color = ['black', 'gold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating box plots\n",
    "# only fare and age are continuous and can really be analyzed with boxplot\n",
    "ax = df_imputed.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute distributions with categories\n",
    "# lets create boxplots of fare by Pclass\n",
    "ax = df_imputed.boxplot(column='Fare', by ='Pclass')\n",
    "df_imputed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lets plot multiple boxplots in a subplot figure with matplotlib\n",
    "\n",
    "vars_to_plot_separate = [['Survived', 'SibSp', 'Pclass'],\n",
    "                          ['Parch'],\n",
    "                          ['Age'],\n",
    "                          ['Fare']]\n",
    "plt.figure(figsize=(10,6))\n",
    "for index, plot_vars in enumerate(vars_to_plot_separate):\n",
    "    plt.subplot(len(vars_to_plot_separate)/2,\n",
    "               2,\n",
    "               index+1) # 0th index takes up first subplot spot\n",
    "    ax = df_imputed.boxplot(column=plot_vars)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
